# LoRACat Environment Configuration
# Copy this file to .env and fill in your values:
#   cp .env.example .env

# --- Hugging Face ---
# Required to download base models and push trained LoRAs
HF_TOKEN=

# --- ComfyUI Connection ---
COMFYUI_ENDPOINT=http://host.docker.internal:8188
COMFYUI_DELAY=2.0

# --- Subject / Trigger ---
TRIGGER_WORD=nyafyi_woman

# --- Z-Image Model Paths ---
# Paths inside container (map to ./models volume)
#
# Required model layout:
#   models/z_image/dit/           → DiT model (from Tongyi-MAI/Z-Image on HuggingFace)
#   models/z_image/vae/           → VAE (reuse from z_image_turbo/split_files/vae/)
#   models/z_image/text_encoder/  → Qwen3 text encoder (reuse from z_image_turbo/split_files/text_encoders/)
DIT_PATH=/models/z_image/dit
VAE_PATH=/models/z_image/vae
TEXT_ENCODER_PATH=/models/z_image/text_encoder

# --- Training Hyperparameters ---
TRAIN_BATCH_SIZE=4
GRADIENT_ACCUMULATION_STEPS=1
LEARNING_RATE=1e-4
NUM_TRAIN_EPOCHS=16
NETWORK_DIM=32
RESOLUTION=1024
MIXED_PRECISION=bf16
DATALOADER_NUM_WORKERS=4
DISCRETE_FLOW_SHIFT=2.0
OUTPUT_NAME=lora_output

# --- Captioning ---
CAPTION_BATCH_SIZE=8

# --- Reproducibility ---
#GLOBAL_SEED=

# --- Weights & Biases (optional) ---
#WANDB_API_KEY=
WANDB_PROJECT=loracat
